{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb774ae-1a04-441a-8080-c00123a4836c",
   "metadata": {},
   "source": [
    "# ****MORPHOLOGICAL PROCESSING****\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4800a50-2b9c-4e31-b4fb-4ea2c772db74",
   "metadata": {},
   "source": [
    "#### Clàudia Blasco (1709871)\n",
    "#### Laura Buide (1710559)\n",
    "#### Carla Cruz (1703329)\n",
    "#### Laia Espluga (1710510)\n",
    "#### Lucía Rodríguez (1705385)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288299f7-9030-4fef-b7b2-2c3c1741ca00",
   "metadata": {},
   "source": [
    "## **1. Introduction**\n",
    "- Project Objective: Explain the fundamental concepts of morphological processing in computer vision.\n",
    "- Definition: Morphological processing is a technique based on set theory, mainly applied to binary images but extendable to grayscale images.\n",
    "- Applications: Shape extraction, noise reduction, edge detection, object segmentation, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add77e4-c076-4cdb-ac7d-0f4486159425",
   "metadata": {},
   "source": [
    "## **2. Mathematical Foundations of Morphological Processing**\n",
    "\n",
    "### 1. Set Theory: Understanding Sets in a Discrete Space\n",
    "Morphological image processing is fundamentally based on **set theory**, where objects in a **binary image** are treated as sets of points in a **discrete space** (typically a 2D grid).  \n",
    "- A **binary image** consists of pixels with values **1 (foreground, object)** and **0 (background)**.  \n",
    "- The object in an image is represented as a **set of foreground pixels**, while the background is treated as the **complementary set**.  \n",
    "\n",
    "For example, an image \\( A \\) containing an object can be represented as:  \n",
    "\n",
    "\n",
    "$$ A = \\{(x,y) \\mid f(x,y) = 1\\} $$\n",
    "\n",
    "\n",
    "where \\( f(x,y) \\) is the pixel value at coordinates \\( (x,y) \\).  \n",
    "\n",
    "In morphological operations, these **sets of pixels** are manipulated using **structuring elements** to **modify shapes, extract features, or remove noise**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bb817b-4fbd-49c4-8a41-ecd1f0708870",
   "metadata": {},
   "source": [
    "### 2. Structuring Elements: Definition and Interaction with the Image  \n",
    "A **structuring element (SE)** is a small matrix (or kernel) that interacts with an image to **probe** and **modify** its structure.  \n",
    "- It is defined as a **binary set of pixels** (typically a small square, cross, or circle).  \n",
    "- The **origin (center)** of the structuring element determines how it overlaps with the image pixels.  \n",
    "\n",
    "Mathematically, if \\( B \\) is a structuring element, it is defined as:  \n",
    "\n",
    "$$ B = \\{(x,y) \\mid b(x,y) = 1\\}$$\n",
    "\n",
    "where \\( b(x,y) \\) represents the pixel values of the structuring element.\n",
    "\n",
    "#### *How the Structuring Element Interacts with an Image*  \n",
    "- It is **placed over each pixel of the image**, aligning its center with the pixel.  \n",
    "- Depending on the operation (erosion, dilation, etc.), the interaction between the structuring element and the underlying pixels **modifies the image**.  \n",
    "\n",
    "For example, a **3×3 cross-shaped structuring element**:\n",
    "\n",
    "\n",
    "$$ B =\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 0 \\\\\n",
    "1 & 1 & 1 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This structuring element is commonly used for morphological operations like **dilation** and **erosion**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd3cdd-3dd7-412f-8ed8-18fee3e68199",
   "metadata": {},
   "source": [
    "### 3. Basic Set Operations in Morphological Processing  \n",
    "Morphological processing uses fundamental **set operations** to manipulate images:\n",
    "\n",
    "#### 3.1 Intersection (A ∩ B)  \n",
    "- Finds **common pixels** between two sets (or binary images).  \n",
    "- In morphological processing, intersection can be used to **detect overlapping objects**.  \n",
    "\n",
    "Mathematically:\n",
    "\n",
    "$$ A \\cap B = \\{(x,y) \\mid (x,y) \\in A \\text{ and } (x,y) \\in B\\} $$\n",
    "\n",
    "#### 3.2 Union (A ∪ B)  \n",
    "- Combines pixels from both sets, **merging objects** in an image.  \n",
    "- Used in **image fusion or combining binary masks**.  \n",
    "\n",
    "Mathematically:\n",
    "\n",
    "$$ A \\cup B = \\{(x,y) \\mid (x,y) \\in A \\text{ or } (x,y) \\in B\\}$$\n",
    "\n",
    "#### 3.3 Complement (¬A)  \n",
    "- **Inverts the image** by flipping foreground and background.  \n",
    "- Used to **highlight objects against the background** or **prepare images for further processing**.  \n",
    "\n",
    "Mathematically:\n",
    "\n",
    "$$ \\neg A = \\{(x,y) \\mid (x,y) \\notin A\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d28b3f-5e74-497f-a99a-b90c4a7030ae",
   "metadata": {},
   "source": [
    "### Application of These Operations in Morphology  \n",
    "This **mathematical foundation** forms the basis for morphological operations like **erosion, dilation, opening, and closing**, which are essential for **shape analysis, noise removal, and feature extraction** in image processing. \n",
    "\n",
    "\n",
    "Here’s a Python code that demonstrates the mathematical applications for morphological image processing. This code applies fundamental morphological operations—erosion, dilation, and complementation—on a binary image, using a structuring element (kernel) to probe and modify the image’s structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ff388f-4279-4b5e-9b72-070fac2821b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAERCAYAAABme8RgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJ8BJREFUeJzt3XucTfX+x/H3NuZ+Y2TMEDNuxxApRKFcyplk3OLISGZCcqJSCJVcCiHiKKLT6UY6x71ORzEulfTrdHSok5LLjAq5G3djZr6/P5y9z+zZey6Yrxnj9Xw8PB7mu9Ze67Nn9net9d5rre9yGGOMAAAAAABAkStT3AUAAAAAAFBaEboBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6LRk7dqwcDsclvfatt96Sw+FQWlpa0RaVQ1pamhwOh9566y1r6wDwP8nJyYqNjS229f/zn/+Un5+fdu/eXWw1FIXXXntN1apV07lz54q7FJRw3vbDsbGxSk5OLtL10LeLBn0bJYXD4dDYsWOLu4xiNWXKFMXFxSk7O/uKrvfWW2/VU089dUXXeaUQunP5/vvv1bt3b1WpUkX+/v6qXLmy7r//fn3//ffFXVqxWL9+vRwOhxYvXlzcpQAXxfnlVV7//u///q+4S7yinnnmGSUmJiomJsbr9KZNm8rhcGjOnDlXuDKpdevWbn8bPz8/Va9eXQMGDNAvv/ziNm9ycrIyMjI0d+7cK14nik/u/hwQEKDKlSsrPj5ef/rTn3TixAmr69+7d6/Gjh2rzZs3W13PpaBvoyTauXOnHn74YdWoUUMBAQEKCwtTixYtNHPmTJ05c6a4y7tmXMq26/jx45o8ebJGjBihMmWKLir+8MMPru33sWPHvM4zYsQIvfrqq/rtt9+KbL0lRdniLqAkWbp0qRITExUREaF+/fqpevXqSktL0xtvvKHFixfr/fffV9euXQu1rGeffVYjR468pDoeeOAB9ezZU/7+/pf0egD/M378eFWvXt2jvVatWle0jtdff/2Kf2PstHnzZqWkpGjjxo1ep2/fvl1ff/21YmNjtWDBAv3xj3+8whVK119/vSZNmiRJysjI0NatW/Xaa6/pk08+0Q8//KCgoCBJUkBAgJKSkjR9+nQ9+uijl3xFEa5Ozv58/vx5/fbbb1q/fr2GDBmi6dOn64MPPtCNN97omvdy9sO57d27V+PGjVNsbKxuuukmt2n07fzRt689H330kf7whz/I399fffr0Uf369ZWRkaENGzZo+PDh+v777zVv3rziLvOakN+2Ky9/+ctflJmZqcTExCKtZf78+YqKitLRo0e1ePFi9e/f32Oezp07KywsTLNnz9b48eOLdP3FzsAYY8yOHTtMUFCQiYuLMwcOHHCbdvDgQRMXF2eCg4PNzp07813OyZMnbZZZZFJTU40k8+abb+Y737p164wks2jRoitTGFBE3nzzTSPJfP311xf92vPnz5tz585ZqKp4PPbYY6ZatWomOzvb6/TnnnvOREZGmiVLlhiHw2FSU1OvaH2tWrUyN9xwg0f7K6+8YiSZVatWubX/61//MpLMmjVrrlSJKGb59ec1a9aYwMBAExMTY06fPp3vcmJiYkxSUtJFr//rr78u1D7zSqNvo6TZtWuXCQkJMXFxcWbv3r0e07dv325mzJhRDJUVniQzZsyY4i6jSFzKtuvGG280vXv3LtI6srOzTWxsrHnyySdN165dTevWrfOcd/DgwSYmJibP7drVisvL/2vq1Kk6ffq05s2bp4oVK7pNu+666zR37lydOnVKU6ZMcbU77xfbunWrevXqpfLly6tly5Zu03I6c+aMHnvsMV133XUKDQ1Vp06dtGfPHo97R7zd0x0bG6uEhARt2LBBTZs2VUBAgGrUqKF33nnHbR1HjhzRsGHD1KBBA4WEhCgsLEzt27fXli1biug39b/39tNPP6l3794KDw9XxYoVNXr0aBlj9Msvv7i+qYqKitK0adPcXp+RkaHnnntOjRs3Vnh4uIKDg3X77bdr3bp1Hus6fPiwHnjgAYWFhalcuXJKSkrSli1bvN6P/uOPP6p79+6KiIhQQECAmjRpog8++KDI3jdKJ+f4Bi+99JJmzJihmjVryt/fX1u3bpUkrV27VrfffruCg4NVrlw5de7cWT/88IPbMk6cOKEhQ4YoNjZW/v7+ioyMVLt27fTNN9+45vF23+epU6c0dOhQVa1aVf7+/qpTp45eeuklGWPc5nM4HBo8eLCWL1+u+vXry9/fXzfccIM+/vjjQr3H5cuXq23btnmeOXrvvffUvXt3JSQkKDw8XO+9916hlut0+PBh9e/fX5UqVZK/v7/q1atXJJeIRkVFSZLKlnW/KKtx48aKiIjQihUrLnsduPq1bdtWo0eP1u7duzV//nxXe2HGVinMPnP9+vW65ZZbJEkPPvig61Jp5z6otPbtUaNG6f777/do//nnnxUXF6cvv/yy0MvKjb5dek2ZMkUnT57UG2+8oejoaI/ptWrV0uOPP+76OTMzU88//7xr3xsbG6unn37a495+53Hw+vXr1aRJEwUGBqpBgwZav369pAtXqzZo0EABAQFq3Lix/v3vf7u9Pjk5WSEhIdq1a5fi4+MVHBysypUra/z48R790ps9e/aob9++rv3cDTfcoL/85S9u8zhvyfzb3/6mcePGqUqVKgoNDVX37t2Vnp6uc+fOaciQIYqMjFRISIgefPBBr2MYzJ8/X40bN1ZgYKAiIiLUs2dPj9sxWrdurfr162vr1q1q06aNgoKCVKVKFbecUtC2y5vU1FR9++23uuuuuwr8nVyML774QmlpaerZs6d69uypzz77TL/++qvXedu1a6fdu3eXyNt5Lgeh+78+/PBDxcbG6vbbb/c6/Y477lBsbKw++ugjj2l/+MMfdPr0aU2cOFEPPfRQnutITk7WrFmzdM8992jy5MkKDAxUhw4dCl3jjh071L17d7Vr107Tpk1T+fLllZyc7Ha/+a5du7R8+XIlJCRo+vTpGj58uL777ju1atVKe/fuLfS6CuO+++5Tdna2XnzxRTVr1kwvvPCCZsyYoXbt2qlKlSqaPHmyatWqpWHDhumzzz5zve748eP685//rNatW2vy5MkaO3asDh48qPj4eLcOlp2drY4dO2rhwoVKSkrShAkTtG/fPiUlJXnU8v333+vWW2/VDz/8oJEjR2ratGkKDg5Wly5dtGzZsiJ937i6pKen69ChQ27/Dh8+7DHfm2++qVmzZmnAgAGaNm2aIiIilJKSovj4eB04cEBjx47Vk08+qY0bN6pFixZuX4oNHDhQc+bMUbdu3TR79mwNGzZMgYGBHuE8J2OMOnXqpJdffll33323pk+frjp16mj48OF68sknPebfsGGDHnnkEfXs2VNTpkzR2bNn1a1bN6/vJac9e/bo559/VqNGjbxO/+qrr7Rjxw4lJibKz89P9957rxYsWJDvMnPKzs5Whw4d9Le//U39+/fXjBkzVK9ePQ0cOFCvvvpqoZeTlZXl+vvs27dPa9eu1ZgxY1SrVi21aNHCY/5GjRrpiy++KPTyUbo98MADkqRVq1Zd1OsKs8+sW7eu6zLHAQMG6N1339W7776rO+64w+syS0vf3rdvn9fB2TIyMrRt2zadOnWqUMuhb19bPvzwQ9WoUUPNmzcv1Pz9+/fXc889p0aNGunll19Wq1atNGnSJPXs2dNj3h07dqhXr17q2LGjJk2apKNHj6pjx45asGCBnnjiCfXu3Vvjxo3Tzp071aNHD4/bPrKysnT33XerUqVKmjJliho3bqwxY8ZozJgx+da4f/9+3XrrrUpJSdHgwYM1c+ZM1apVS/369dOMGTM85p80aZI++eQTjRw5Un379tXSpUs1cOBA9e3bVz/99JPGjh2re++9V2+99ZYmT57s9toJEyaoT58+ql27tqZPn64hQ4ZozZo1uuOOOzzugz569KjuvvtuNWzYUNOmTVNcXJxGjBihlStXSrr4bZck160qeW1XLtWCBQtUs2ZN3XLLLerYsaOCgoK0cOFCr/M2btxYkkrfdqA4T7OXFMeOHTOSTOfOnfOdr1OnTkaSOX78uDHGmDFjxhhJJjEx0WNe5zSnTZs2GUlmyJAhbvMlJyd7XMbivIwu52VgMTExRpL57LPPXG0HDhww/v7+ZujQoa62s2fPmqysLLd1pKamGn9/fzN+/Hi3Nl3i5eXO9zZgwABXW2Zmprn++uuNw+EwL774oqv96NGjJjAw0O1yvszMTI9Ld48ePWoqVapk+vbt62pbsmSJkeR2GVJWVpZp27atR+133nmnadCggTl79qyrLTs72zRv3tzUrl073/eI0snZj7z98/f3d83n7AthYWEet5bcdNNNJjIy0hw+fNjVtmXLFlOmTBnTp08fV1t4eLgZNGhQvvUkJSWZmJgY18/Lly83kswLL7zgNl/37t2Nw+EwO3bscLVJMn5+fm5tW7ZsMZLMrFmz8l1vSkqKkWQ+/PBDr9MHDx5sqlat6rqMa9WqVUaS+fe//53vcp0++eQTI8msX7/erb13794mOjraY3vkTatWrbz+nerWrWt27drl9TUDBgwwgYGBhaoRV7/C3C4SHh5ubr75ZtfPuffDxnheXl7YfWZ+l2iW1r6dlJRkWrRo4dG+fft2I8msXr26wGXQt68t6enphTqedtq8ebORZPr37+/WPmzYMCPJrF271tXmPA7euHGjq825/wkMDDS7d+92tc+dO9dIMuvWrXO1JSUlGUnm0UcfdbVlZ2ebDh06GD8/P3Pw4EFXe+7j8n79+pno6Ghz6NAhtzp79uxpwsPDXbe1OI+Z69evbzIyMlzzJSYmGofDYdq3b+/2+ttuu81t25GWlmZ8fHzMhAkT3Ob77rvvTNmyZd3anX3rnXfecbWdO3fOREVFmW7durnaLvby8meffdZIMidOnPCYtn//frNv374C/+V+bUZGhqlQoYJ55plnXG29evUyDRs2zLMOPz8/88c//rFQNV8tONMtuUY9DQ0NzXc+5/Tjx4+7tQ8cOLDAdTgvFXvkkUfc2h999NFC11mvXj23M/EVK1ZUnTp1tGvXLlebv7+/a6TBrKwsHT58WCEhIapTp47bpa5FIecACD4+PmrSpImMMerXr5+rvVy5ch41+vj4yM/PT9KFs2RHjhxRZmammjRp4lbjxx9/LF9fX7erB8qUKaNBgwa51XHkyBGtXbtWPXr00IkTJ9zOZsbHx2v79u3as2dPkb53XD1effVVrV692u2f81vgnLp16+Z2a8m+ffu0efNmJScnKyIiwtV+4403ql27dvrHP/7haitXrpy++uqri7qa5B//+Id8fHz02GOPubUPHTpUxhiPGu+66y7VrFnTrY6wsDC3vuWN82xZ+fLlPaZlZmbqr3/9q+677z7X5alt27ZVZGRkoc+Iff7556pUqZJatWrl1p6YmKh9+/Zp586dhVpObGys299nxowZSk9PV/v27XXw4EGP+cuXL68zZ87o9OnThVo+Sr+QkJCLHsXcxj6ztPTtokLfvnY4j48LOp52cu5Hc18BMnToUEnyuLq0Xr16uu2221w/N2vWTNKFz3a1atU82r31ocGDB7v+77y9IyMjQykpKV5rNMZoyZIl6tixo4wxblfNxcfHKz093WNb0adPH/n6+rrVY4xR37593eZr1qyZfvnlF2VmZkq6cIl8dna2evTo4baeqKgo1a5d2+M2zJCQEPXu3dv1s5+fn5o2bVrgtiM/hw8fVtmyZRUSEuIxrV69eoqOji7w30svveT2upUrV+rw4cNuA7MlJiZqy5YteT4dqnz58jp06NAlv4+SiNHL9b+NQ0E767zCubeRkXPbvXu3ypQp4zHvxYygnHOD4lS+fHkdPXrU9XN2drZmzpyp2bNnKzU1VVlZWa5pFSpUKPS6LqWe8PBwBQQE6LrrrvNoz32Z3Ntvv61p06bpxx9/1Pnz513tOX8/u3fvVnR0tGtkU6fcv7MdO3bIGKPRo0dr9OjRXms9cOCAqlSpUvg3h1KjadOmatKkSYHz5e6bzssq69Sp4zFv3bp19cknn+jUqVMKDg7WlClTlJSUpKpVq6px48a655571KdPH9WoUSPP9e3evVuVK1f22J7UrVvXbf1Ohen/+TFe7llbtWqVDh48qKZNm2rHjh2u9jZt2mjhwoWaPHlygY8L2b9/v9fanI8v2rdvn2rXrl1gfcHBwW73kN19991q2bKlmjRpohdffNFjbAjn+2GEYzidPHlSkZGRF/UaG/vM0tK3iwp9+9oRFhYmqeDjaSfnsXHu47qoqCiVK1euwL4SHh4uSapatarX9tx9qEyZMh775d/97neS5HbLWE4HDx7UsWPHNG/evDxHXD9w4MAl15mdna309HRVqFBB27dvlzEmz31mziAvXXgyQO5+Ur58eX377bdeX3+5li5dqoyMjHznyfklgNP8+fNVvXp1+fv7u7ZHNWvWVFBQkBYsWKCJEyd6vMYYU+q2AYRuXfjQR0dHF/gh/fbbb1WlShXXRsUpMDDQZnkuPj4+Xttz7nAnTpyo0aNHq2/fvnr++ecVERGhMmXKaMiQIUX+SBNv9RSmxvnz5ys5OVldunTR8OHDFRkZKR8fH02aNKnQZ8Vycr6vYcOGKT4+3us8V/rxULj6XE4/7tGjh26//XYtW7ZMq1at0tSpUzV58mQtXbpU7du3L5L6CtO3vHEGB28H8M4zXj169PD62k8//VRt2rTJd/kZGRmuK1dycj7ysKAddH6cgy3mHBPC6ejRowoKCrpi21+UbL/++qvS09Mvelt/JfeZeSmpfdvPz89r/3UO/HQ5jzWlb5dOYWFhqly5sv7zn/9c1OsKG67y6iuX2ocKw7kd6N27t9cxhSS5Paowv3oKqjM7O1sOh0MrV670Om/us8823neFChWUmZmpEydOeHxxmN+94E4BAQFuPx8/flwffvihzp496/XLhPfee08TJkzw+AwcO3bM4yTe1Y7Q/V8JCQl6/fXXtWHDBtcI5Dl9/vnnSktL08MPP3xJy4+JiVF2drZSU1PdPnQ5v4EuCosXL1abNm30xhtvuLWXpA/v4sWLVaNGDS1dutStk+UeyCImJkbr1q3T6dOn3c525/6dOb+19PX1LfLRFnHtcp6p3bZtm8e0H3/8Udddd52Cg4NdbdHR0XrkkUf0yCOP6MCBA2rUqJEmTJiQZ+iOiYlRSkqKx47txx9/dFv/5YqLi5N0YUTSnE6dOqUVK1bovvvuU/fu3T1e99hjj2nBggUFHpjblpWVpZMnT3q0p6amus4cAu+++64k5fnFa14Ku8+8mDMupaVvR0VF6eeff/Zod559dI5Afqno26VTQkKC5s2bpy+//NLtUnBvnMfG27dvd/ub79+/X8eOHSuyvuKUnZ2tXbt2uc5uS9JPP/0kSR5PIHCqWLGiQkNDlZWVZf0Ys2bNmjLGqHr16m41Xo6LPVucc7uS+8uES7F06VKdPXtWc+bM8cgh27Zt07PPPqsvvvjCLXvt2bNHGRkZpW47wD3d/zV8+HAFBgbq4Ycf9rgU+siRIxo4cKCCgoI0fPjwS1q+80Bg9uzZbu2zZs26tILz4OPj4/EN16JFi0rUPc3Ob+Zy1vnVV195PH4kPj5e58+f1+uvv+5qy87O9hgROTIyUq1bt9bcuXO1b98+j/V5u2cMKEh0dLRuuukmvf32224jhv7nP//RqlWrdM8990i6cOCYnp7u9trIyEhVrlzZ66NAnO655x5lZWXplVdecWt/+eWX5XA4iuwMeZUqVVS1alX961//cmtftmyZTp06pUGDBql79+4e/xISErRkyZJ834Nt69at08mTJ9WwYUOPad98802hR8dF6bZ27Vo9//zzql69utdHXOWnsPtM5xdsuUcP9qa09O2WLVtq//79+vTTT93aFy5cqOjoaLf70C8Wfbv0euqppxQcHKz+/ftr//79HtN37typmTNnSpJrP5p7BPDp06dL0kU94aewcvZLY4xeeeUV+fr66s477/Q6v4+Pj7p166YlS5Z4PYNflMeY9957r3x8fDRu3DiP7ZIxpsAnGnhzMdsuSa4vSnJvVwrrlltucbu8fv78+apRo4YGDhzosS0aNmyYQkJCPMaZ2LRpkySVuu0AZ7r/q3bt2nr77bd1//33q0GDBurXr5+qV6+utLQ0vfHGGzp06JAWLlx4yTuZxo0bq1u3bpoxY4YOHz6sW2+9VZ9++qnrG7aium8hISFB48eP14MPPqjmzZvru+++04IFC/K9t/RKS0hI0NKlS9W1a1d16NBBqampeu2111SvXj23b727dOmipk2baujQodqxY4fi4uL0wQcf6MiRI5Lcf2evvvqqWrZsqQYNGuihhx5SjRo1tH//fn355Zf69ddfi/Q55bi6rFy50nWGKafmzZsX2C+mTp2q9u3b67bbblO/fv105swZzZo1S+Hh4Ro7dqykC/euXX/99erevbsaNmyokJAQpaSk6Ouvv/a4VzGnjh07qk2bNnrmmWeUlpamhg0batWqVVqxYoWGDBlyWQe0uXXu3FnLli1zu0dqwYIFqlChQp47tU6dOun111/XRx99pHvvvbfIaslLenq66xnLmZmZ2rZtm+bMmaPAwECNHDnSbd5NmzbpyJEj6ty5s/W6ULI4+3NmZqb279+vtWvXavXq1YqJidEHH3zgcWljQQq7z6xZs6bKlSun1157TaGhoQoODlazZs28julSWvr2XXfdpaZNm6pjx4569NFHdf3112vNmjVasmSJXnnllULfE07fvrbUrFlT7733nu677z7VrVtXffr0Uf369ZWRkaGNGzdq0aJFSk5OliQ1bNhQSUlJmjdvno4dO6ZWrVrpn//8p95++2116dKlyK+0CggI0Mcff6ykpCQ1a9ZMK1eu1EcffaSnn37abSDV3F588UWtW7dOzZo100MPPaR69erpyJEj+uabb5SSkuI6Lr1cNWvW1AsvvKBRo0YpLS1NXbp0UWhoqFJTU7Vs2TINGDBAw4YNu+hlFnbbJV24erR+/fpKSUnxGPitMBYtWuT6/969e7Vu3TqPQSWd/P39FR8fr0WLFulPf/qT65711atXq1q1arr55psvev0l2hUZI/0q8u2335rExEQTHR1tfH19TVRUlElMTDTfffedx7zOx5HkfMxA7mk5nTp1ygwaNMhERESYkJAQ06VLF7Nt2zYjye0xW3k9MqxDhw4e62nVqpVp1aqV6+ezZ8+aoUOHmujoaBMYGGhatGhhvvzyS4/5iuKRYbnfd1JSkgkODvZa4w033OD6OTs720ycONHExMQYf39/c/PNN5u///3vHo9dMcaYgwcPml69epnQ0FATHh5ukpOTzRdffGEkmffff99t3p07d5o+ffqYqKgo4+vra6pUqWISEhLM4sWL832PKJ3ye2RYzs++sy9MnTrV63JSUlJMixYtTGBgoAkLCzMdO3Y0W7dudU0/d+6cGT58uGnYsKEJDQ01wcHBpmHDhmb27Nluy/H2+T5x4oR54oknTOXKlY2vr6+pXbu2mTp1qusRP06SvD6SLPfjj/LyzTffGEnm888/N8ZceOxH2bJlzQMPPJDna06fPm2CgoJM165d8132yJEjTa9evTzad+/eberUqeP2eJe85H6skMPhMBEREaZTp05m06ZNHvOPGDHCVKtWzeP3hNIrd3/28/MzUVFRpl27dmbmzJmuR3nmVNhHhhVmn2mMMStWrDD16tUzZcuWdduGlNa+bYwxhw4dMn379jUVK1Y0vr6+Ji4uzsyZM6fA1znRt69dP/30k3nooYdMbGys8fPzM6GhoaZFixZm1qxZbo93PX/+vBk3bpypXr268fX1NVWrVjWjRo1ym8eYvI+DvfUhb/t15zHqzp07ze9//3sTFBRkKlWqZMaMGePx2EDlemSYMRf61qBBg0zVqlVd+eDOO+808+bNc83j7ZjZmLwfeZjX8fSSJUtMy5YtTXBwsAkODjZxcXFm0KBBZtu2ba55ch9b53yfubdHeW278jJ9+nQTEhLiehTapZo2bZqRZNasWZPnPG+99ZaRZFasWGGMufBo4OjoaPPss89e1rpLIocxRTDKAC7Z5s2bdfPNN2v+/PkXfVnctWr58uXq2rWrNmzYoBYtWhR3OcBV4c4771TlypVd975erc6dO6fY2FiNHDlSjz/+eHGXAxQ7+jZQsOTkZC1evNjrOAJwl56erho1amjKlClujwG+EpYvX65evXpp586dio6OvqLrto17uq+gM2fOeLTNmDFDZcqUKdSIgNei3L+zrKwszZo1S2FhYWrUqFExVQVcfSZOnKi//vWvHo9gudq8+eab8vX11cCBA4u7FKBEoG8DKErh4eF66qmnNHXq1Cv2FAenyZMna/DgwaUucEsSZ7qvoHHjxmnTpk1q06aNypYtq5UrV2rlypUaMGCA5s6dW9zllUj9+/fXmTNndNttt+ncuXNaunSpNm7cqIkTJ2rUqFHFXR4AAABKOM50o7gxkNoV1Lx5c61evVrPP/+8Tp48qWrVqmns2LF65plniru0Eqtt27aaNm2a/v73v+vs2bOqVauWZs2apcGDBxd3aQAAAABQIM50AwAAAABgCfd0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhS6IHUHA6HzToAXIZLHZqBfg2UXJcz5EpJ6NsMGVNylITPA/6HvgFcezjTDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWlC3uAi6GMaa4S8B/ORyO4i4BAJAH9pfIqaR8Hjh2uPrxNyw5Skq/RuFwphsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAAS8oWdwEXw+FwFHcJJYIxprhLAACUYCVhf8m+Cih96NcXlIRtLK4unOkGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAkrLFXQCuTsaY4i5BkuRwOIq7BACAFyVh+1xS9lW4oCT8PUrC5xIoCiXls1wS+vXVgDPdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEvKFncBuHgOh6O4S5AxprhLkFQy6igJfw8AgKeSsH0uCfsp/A9/DxSFkvA5KgnbN6lk1FES/h4F4Uw3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwJKyxV0Ark4Oh6O4SwAAoMQrCftLY0xxl1Bi8PdAacHn6OrCmW4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJQ5jjCnuIgAAAAAAKI040w0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAl/w+FP5dIHfZkPwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import binary_erosion, binary_dilation, binary_closing, binary_opening\n",
    "\n",
    "# Create a sample binary image (foreground = 1, background = 0)\n",
    "image = np.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "# Define a structuring element (3x3 cross-shaped)\n",
    "structuring_element = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, 1, 1],\n",
    "    [0, 1, 0]\n",
    "])\n",
    "\n",
    "# Plot the original image\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Apply erosion (Intersection with structuring element)\n",
    "eroded_image = binary_erosion(image, structure=structuring_element).astype(int)\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(eroded_image, cmap='gray')\n",
    "plt.title('Erosion (A ∩ B)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Apply dilation (Union with structuring element)\n",
    "dilated_image = binary_dilation(image, structure=structuring_element).astype(int)\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(dilated_image, cmap='gray')\n",
    "plt.title('Dilation (A ∪ B)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Apply complement (Inversion of image)\n",
    "complement_image = np.logical_not(image).astype(int)\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(complement_image, cmap='gray')\n",
    "plt.title('Complement (¬A)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Show all images\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6fec4f-80e0-43e0-9253-9d0492e4777a",
   "metadata": {},
   "source": [
    "#### Explanation of the Code:\n",
    "- **Original Image**: A 7x7 binary image with some foreground objects (1's) and background (0's).\n",
    "- **Structuring Element**: A 3x3 cross-shaped structuring element used for morphological operations.\n",
    "- **Erosion**: The operation of intersection between the image and the structuring element. Only pixels fully surrounded by the structuring element (1's) remain in the image.\n",
    "- **Dilation**: The operation of union between the image and the structuring element. Pixels are added to the image where the structuring element overlaps.\n",
    "- **Complement**: Inverts the image, changing foreground pixels (1's) to background pixels (0's) and vice versa.\n",
    "\n",
    "#### How it connects to the mathematical applications:\n",
    "- The **erosion** operation is equivalent to the intersection $(A \\cap B)$, which removes pixels from the boundary of the foreground.\n",
    "- The **dilation** operation is equivalent to the union $(A \\cup B)$, which adds pixels to the boundary of the foreground.\n",
    "- The **complement** operation inverts the image $( \\neg A)$, flipping the 1's and 0's.\n",
    "\n",
    "Running this code in a Jupyter notebook will display the original image and the results of the morphological operations, visually demonstrating the mathematical concepts of intersection, union, and complement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4029ecb3-fba3-4f6c-918c-c2fe1bdb5ad1",
   "metadata": {},
   "source": [
    "## **3. Basic Morphological Operations**\n",
    "Morphological processing is a technique used in image processing to modify and analyze shapes in an image. It works mainly with binary images (black-and-white images) and uses a structuring element, which is a small shape that interacts with objects in the image. \n",
    "\n",
    "The four basic operations are Erosion, Dilation, Opening, and Closing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd89f80-485f-4568-904e-ddd261b7df38",
   "metadata": {},
   "source": [
    "### 1. Erosion: Making Objects Smaller\n",
    "\n",
    "Erosion is a process that shrinks (become or make smaller in size or amount) objects in an image. It works by removing pixels from the edges of objects based on the structuring element. If the structuring element does not fully fit inside the object, that part of the object disappears.\n",
    "\n",
    "**Uses of Erosion**:\n",
    "- Removes small details or noise from an image.\n",
    "- Separates objects that are touching.\n",
    "- Makes objects look thinner.\n",
    "\n",
    "**Example**: If you apply erosion to a text image, the letters will become thinner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd23a7-8165-4f18-a220-7b540cc31e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in grayscale\n",
    "image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Convert to binary image (ensure background is black and text is white)\n",
    "_, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Define the kernel for erosion\n",
    "kernel = np.ones((4, 4), np.uint8)  # Kernel size 4x4\n",
    "\n",
    "# Apply erosion\n",
    "eroded = cv2.erode(binary, kernel, iterations=1)\n",
    "\n",
    "# Display the original and eroded images\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(binary, cmap='gray')\n",
    "plt.title(\"Binary Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(eroded, cmap='gray')\n",
    "plt.title(\"Eroded Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b300349c-3705-4285-b601-9f0eaa946104",
   "metadata": {},
   "source": [
    "### 2. Dilation: Making Objects Bigger\n",
    "Dilation is the opposite of erosion. Instead of removing pixels, it adds pixels to the edges of objects, making them larger. If any part of the structuring element touches the object, the object grows in size.\n",
    "\n",
    "**Uses of Dilation**:\n",
    "- Fills small holes inside objects.\n",
    "- Connects broken parts of an object.\n",
    "- Makes objects thicker.\n",
    "\n",
    "**Example**: If you apply dilation to a broken line, the gaps will be filled, making it a complete line.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f2d1e-641c-490a-9319-155a362c3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in grayscale\n",
    "image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Convert to binary image (ensure background is black and text is white)\n",
    "_, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Define the kernel for dilation\n",
    "kernel = np.ones((4, 4), np.uint8)  # Kernel size 4x4\n",
    "\n",
    "# Apply dilation\n",
    "dilated = cv2.dilate(binary, kernel, iterations=1)\n",
    "\n",
    "# Display the original and dilated images\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(binary, cmap='gray')\n",
    "plt.title(\"Binary Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(dilated, cmap='gray')\n",
    "plt.title(\"Dilated Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250c918-c07b-4c74-abc6-e0201c0ec4ba",
   "metadata": {},
   "source": [
    "### 3. Opening: Removing Small Objects\n",
    "Opening is a combination of erosion followed by dilation.\n",
    "\n",
    "First, erosion removes small objects (such as noise).\n",
    "Then, dilation restores the main shapes of the image.\n",
    "\n",
    "**Uses of Opening**:\n",
    "- Removes random small white dots (noise).\n",
    "- Helps smooth object boundaries.\n",
    "- Keeps important parts of the image while removing unwanted details.\n",
    "\n",
    "**Example**: If an image has small white specks (like dust on a black background), opening can remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495cdedd-1d1f-4383-964d-40159a621e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in grayscale\n",
    "image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Verify if the image loaded correctly\n",
    "if image is None:\n",
    "    raise FileNotFoundError(\"⚠️ Image not found. Check the filename and path.\")\n",
    "\n",
    "# Convert to binary (Thresholding)\n",
    "_, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Define a structuring element (kernel)\n",
    "kernel = np.ones((5,5), np.uint8)  \n",
    "\n",
    "# Apply Morphological Opening (Erosion followed by Dilation)\n",
    "opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Display the original and processed images\n",
    "titles = [\"Original Image\", \"Opening (Erosion → Dilation)\"]\n",
    "images = [binary, opening]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb9c5e-f7e3-4db7-85d7-25ebf621e1ea",
   "metadata": {},
   "source": [
    "### 4. Closing: Filling Small Gaps\n",
    "Closing is the opposite of opening. It is a dilation followed by erosion.\n",
    "\n",
    "First, dilation expands the objects, filling small holes and gaps.\n",
    "Then, erosion restores the original shape without bringing back the gaps.\n",
    "\n",
    "**Uses of Closing**:\n",
    "- Fills small holes in an image.\n",
    "- Connects objects that are close together.\n",
    "- Makes object boundaries smoother.\n",
    "\n",
    "**Example**: If an object has tiny black holes inside, closing will fill them up, making the object solid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d6cfe-a2dd-49ab-9d64-f9c4c66edcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in grayscale\n",
    "image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Verify if the image loaded correctly\n",
    "if image is None:\n",
    "    raise FileNotFoundError(\"⚠️ Image not found. Check the filename and path.\")\n",
    "\n",
    "# Convert to binary (Thresholding)\n",
    "_, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Define a structuring element (kernel)\n",
    "kernel = np.ones((5,5), np.uint8)  \n",
    "\n",
    "# Apply Morphological Closing (Dilation followed by Erosion)\n",
    "closing = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Display the original and processed images\n",
    "titles = [\"Original Image\", \"Closing (Dilation → Erosion)\"]\n",
    "images = [binary, closing]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4247507e-7e00-4df5-9c47-677e2617f086",
   "metadata": {},
   "source": [
    "## **4. Advanced Morphological Operations**\n",
    "Advanced morphological operations extend basic transformations like erosion and dilation to more complex image processing tasks. These operations are widely used in computer vision, medical imaging, and pattern recognition. \n",
    "\n",
    "The main advanced operations include Morphological Gradient, Top-Hat/Black-Hat and Skeletonization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e6adbd",
   "metadata": {},
   "source": [
    "### 1. Morphological Gradient\n",
    "\n",
    "Morphological Gradient is a process that highlights the edges of objects by subtracting the eroded version of an image from the dilated version.\n",
    "\n",
    "**Uses of Morphological Gradient**:\n",
    "- Edge detection\n",
    "- Object boundary enhancement\n",
    "\n",
    "**Example**: If you apply this process to a text image, it will extract the its edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88bf7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in grayscale\n",
    "image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Convert to binary image (ensure background is black and text is white)\n",
    "_, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Define the kernel for morphological operations\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "# Calculate the morphological gradient\n",
    "gradient = cv2.morphologyEx(binary, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "# Display the original and gradient images\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Display original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(binary, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Display gradient image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(gradient, cmap='gray')\n",
    "plt.title(\"Morphological Gradient\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac262f",
   "metadata": {},
   "source": [
    "### 2. Top-Hat Transformation\n",
    "\n",
    "Top-Hat is a transformation that extracts small bright regions from the image by subtracting the opened image from the original.\n",
    "\n",
    "**Uses of Top-Hat Transformation**:\n",
    "- Enhancing bright details.\n",
    "- Enhancing contrast (useful for faded or scanned text)\n",
    "\n",
    "**Example**: If you apply this process to a text image with an uneven background, it will enhance the text while removing background noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ccaafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in grayscale\n",
    "image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Verify if the image loaded correctly\n",
    "if image is None:\n",
    "    raise FileNotFoundError(\"⚠️ Image not found. Check the filename and path.\")\n",
    "\n",
    "# Convert to binary (Thresholding)\n",
    "_, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Define a structuring element (kernel)\n",
    "kernel = np.ones((4,4), np.uint8)  \n",
    "\n",
    "# Apply Top-Hat Transform (Extracts bright regions)\n",
    "tophat = cv2.morphologyEx(binary, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "# Display the original and processed images\n",
    "titles = [\"Original Image\", \"Top-Hat (Highlight Bright Areas)\"]\n",
    "images = [binary, tophat]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed0a819",
   "metadata": {},
   "source": [
    "### 3. Black-Hat Transformation\n",
    "\n",
    "Black-Hat is a transformation that extracts dark regions by subtracting the original image from its closed version.\n",
    "\n",
    "**Uses of Black-Hat Transformation**:\n",
    "- Detecting dark regions in a bright background.\n",
    "- Removing uneven shadows in text images.\n",
    "\n",
    "**Example**: If you apply this process to a text image with an light background, it will extract shadows and dark areas, making the text more distinguishable. Similar to Top-Hat Transformations, it also removes background noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb0994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in grayscale\n",
    "image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Verify if the image loaded correctly\n",
    "if image is None:\n",
    "    raise FileNotFoundError(\"⚠️ Image not found. Check the filename and path.\")\n",
    "\n",
    "# Convert to binary (Thresholding)\n",
    "_, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Define a structuring element (kernel)\n",
    "kernel = np.ones((4,4), np.uint8)  \n",
    "\n",
    "# Apply Black-Hat Transform (Extracts dark regions)\n",
    "blackhat = cv2.morphologyEx(binary, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "# Display the original and processed images\n",
    "titles = [\"Original Image\", \"Black-Hat (Highlight Dark Areas)\"]\n",
    "images = [binary, blackhat]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c6a2e",
   "metadata": {},
   "source": [
    "### 4. Skeletonization\n",
    "\n",
    "This process reduces objects to their thin, connected centerlines, preserving topology.\n",
    "\n",
    "**Uses of Skeletonization**:\n",
    "- Reducing text to its centerlines.\n",
    "- Character recognition and feature extraction.\n",
    "\n",
    "**Example**: If you apply this process to a text image, it will thin the letters to their minimal representation while preserving connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f732e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in grayscale\n",
    "image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Convert to binary image (ensure background is black and text is white)\n",
    "_, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Fast skeletonization with OpenCV\n",
    "binary_skel = binary.copy()\n",
    "skel = np.zeros(binary_skel.shape, np.uint8)\n",
    "element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n",
    "\n",
    "while True:\n",
    "    eroded_temp = cv2.erode(binary_skel, element)\n",
    "    temp = cv2.dilate(eroded_temp, element)\n",
    "    temp = cv2.subtract(binary_skel, temp)\n",
    "    skel = cv2.bitwise_or(skel, temp)\n",
    "    binary_skel = eroded_temp.copy()\n",
    "    if cv2.countNonZero(binary_skel) == 0:\n",
    "        break\n",
    "\n",
    "# Display the skeletonized image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(skel, cmap='gray')\n",
    "plt.title(\"Skeletonized Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b290c662-e302-4e29-9b6b-12ada5a98520",
   "metadata": {},
   "source": [
    "## **5. Practical Implementation**\n",
    "- Common Libraries: OpenCV (Python), MATLAB, scikit-image.\n",
    "- Code Examples: Implementation of each operation in Python using OpenCV.\n",
    "- Before/After Comparison: Visualizing results by applying different operations to an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c9aae-1503-4ae7-a119-57a91ee02a34",
   "metadata": {},
   "source": [
    "## **6. Applications and Use Cases**\n",
    "- Computer Vision: Object recognition in medical, industrial, and security images.\n",

  In the medical, it is useful to detect and segment atomic structures



    "- Image Reconstruction: Noise removal and image quality enhancement.\n",
    "- Document Processing: Text recognition in scanned documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951fa25-3d0c-47a5-af71-87a5562c0fc1",
   "metadata": {},
   "source": [
    "## **7. Conclusion and Discussion**\n",
    "- Summary of key concepts.\n",
    "- Limitations of morphological processing.\n",
    "- Future improvements and integration with neural networks.\n",
    "- Q&A session and audience discussion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc66f9-9238-4848-b90a-ce9757f44f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
